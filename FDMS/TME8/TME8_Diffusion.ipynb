{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modèle de diffusion : INDEPENDENT CASCADES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#IMPORT\n",
    "import numpy as np\n",
    "import copy\n",
    "import operator\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Objectif\n",
    "Le but est de prédire à partir d'un ensemble d'utilisateur infectés quels seront les utilisateurs inféctés par la suite. Pour cela nous allons représenter liens entre utilisateurs sous forme de graphe, les probabilités d'infection entre deux utilisateur seront alors représentés par les poids des arcs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lecture des donnees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "file_train = open(\"cascades_train.txt\")\n",
    "file_test = open(\"cascades_test.txt\")\n",
    "\n",
    "\n",
    "data_train=[]\n",
    "for i in file_train.readlines():\n",
    "    tab = [[float(j.split(\":\")[0]),float(j.split(\":\")[1])] for j in i.split(\";\")[:-1]]\n",
    "    tab.sort(key=lambda x: x[1])\n",
    "    data_train.append(tab)\n",
    "\n",
    "    \n",
    "data_test=[]\n",
    "for i in file_test.readlines():\n",
    "    tab = [[float(j.split(\":\")[0]),float(j.split(\":\")[1])] for j in i.split(\";\")[:-1]]\n",
    "    tab.sort(key=lambda x: x[1])\n",
    "    data_test.append(tab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creation des liste de successeurs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def getSuccsOfTab(tab):\n",
    "    succ=[]\n",
    "    for i in tab:\n",
    "        succ_i=[]\n",
    "        for j in tab:\n",
    "            if(i[1]<j[1]):\n",
    "                succ_i.append(j[0])\n",
    "        succ.append([i[0],succ_i])\n",
    "    return succ\n",
    "\n",
    "def unique(liste):\n",
    "    seen=set()\n",
    "    seen_add =seen.add\n",
    "    return [x for x in liste if not(x in seen or seen_add(x))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "succs_train = []\n",
    "for line in data_train:\n",
    "    succs_train.append(getSuccsOfTab(line))\n",
    "\n",
    "succs_test = []\n",
    "for line in data_test:\n",
    "    succs_test.append(getSuccsOfTab(line))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Création des graphes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#optimisation au niveau du temps possible\n",
    "def getGraph(succs):\n",
    "    graph={}\n",
    "    for h in succs:\n",
    "        for i in h:\n",
    "            try:\n",
    "                for j in i[1]:\n",
    "                    graph[i[0]].append(j)\n",
    "                graph[i[0]]=unique(graph[i[0]])\n",
    "                graph[i[0]].sort()\n",
    "            except KeyError:\n",
    "                graph[i[0]]=i[1]\n",
    "    return graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "graph_train = getGraph(succs_train)\n",
    "graph_test = getGraph(succs_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apprentissage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fonction pour avoir la probabilité, P chapeau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#liste correspond a un D\n",
    "def getListPrec(liste):\n",
    "    prec=[]\n",
    "    for i in liste:\n",
    "        if (i[1]>1):\n",
    "            p=[]\n",
    "            for j in liste:\n",
    "                if (i[1]>j[1]):\n",
    "                    p.append(j[0])\n",
    "            prec.append((i[0],p))\n",
    "    return prec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#listePrec obtenue avec getListPrec dun D\n",
    "def getProbaOfList(listePrec,graph_weight_d):\n",
    "    a={}\n",
    "    for i in listePrec:\n",
    "        prod=1\n",
    "        for pre in i[1]:\n",
    "            prod= prod *(1 - graph_weight_d[pre][i[0]])\n",
    "        a[i[0]]=1-prod\n",
    "    return a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#dicoPrec obtenue avec constructAllDicoPrec \n",
    "def getProbaOfDicoPrec(dicoPrec,graph_weight_d):\n",
    "    a={}\n",
    "    for i in dicoPrec:\n",
    "        prod=1\n",
    "        for pre in dicoPrec[int(i)]:\n",
    "            prod= prod *(1 - graph_weight_d[int(pre)][int(i)])\n",
    "        a[i]=1-prod\n",
    "    return a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#fonction permettant de savoir si il existe une infection de l'element u sur v, lors d'un episode D\n",
    "#si oui retourne les indices\n",
    "def existLinkUV(d,u,v):\n",
    "    listeSucc = getSuccsOfTab(d)\n",
    "    listeU = [i[0] for i in listeSucc]\n",
    "    if u in listeU:\n",
    "        indiceU = np.where(np.array(listeU)==u)[0][0]\n",
    "        listeV = listeSucc[indiceU][1]\n",
    "        if v in listeV:\n",
    "            return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def constructDicoDsucc(d):\n",
    "    dico1={}\n",
    "    dico={}\n",
    "    for i in d:\n",
    "        dico1[i[0]]=i[1]\n",
    "        dico[i[0]]={}\n",
    "    for i in dico:\n",
    "        for j in d:\n",
    "            if(dico1[i]<j[1]):\n",
    "                dico[i][j[0]]=j[1]\n",
    "    return dico\n",
    "\n",
    "def constructDicoDprec(d):\n",
    "    dico1={}\n",
    "    dico={}\n",
    "    for i in d:\n",
    "        dico1[i[0]]=i[1]\n",
    "        dico[i[0]]={}\n",
    "    for i in dico:\n",
    "        for j in d:\n",
    "            if(dico1[i]>j[1]):\n",
    "                dico[i][j[0]]=j[1]\n",
    "    return dico\n",
    "\n",
    "def constructAlldicosSucc(data):\n",
    "    listeAllDico=[]\n",
    "    for i in data:\n",
    "        listeAllDico.append(constructDicoDsucc(i))\n",
    "    return listeAllDico\n",
    "\n",
    "\n",
    "def constructAlldicosPrec(data):\n",
    "    listeAllDico=[]\n",
    "    for i in data:\n",
    "        listeAllDico.append(constructDicoDprec(i))\n",
    "    return listeAllDico\n",
    "        \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Poids du graphe assignés en random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#creation des poids du graph dico\n",
    "def getGraphWeightRandom(graph):\n",
    "    graph_weight_d={}\n",
    "    for i in graph:\n",
    "        dico={}\n",
    "        for e in graph[i]:\n",
    "            rando=np.random.rand()\n",
    "            dico[e]=rando\n",
    "        graph_weight_d[i]=dico\n",
    "    return graph_weight_d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gInit_train = getGraphWeightRandom(graph_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fonction d'apprentissage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#ne fonctionne pas\n",
    "def fitModele(data_train,nbIt=1,eps=1e-1):\n",
    "    succs_train = []\n",
    "    for line in data_train:\n",
    "        succs_train.append(getSuccsOfTab(line))\n",
    "    graph_train = getGraph(succs_train)   \n",
    "        \n",
    "    #init    \n",
    "    graph_cur = getGraphWeightRandom(graph_train)\n",
    "    \n",
    "    #it=0\n",
    "    #ep=100000\n",
    "    #while((it<nbIt) & (ep>eps)):\n",
    "        #probas_chapiteau=[getProbaOfList(getListPrec(d),graph_cur) for d in data_train]\n",
    "        \n",
    "    \n",
    "    #loop for : utilisateur u vers v \n",
    "    for m,u in enumerate(graph_cur):\n",
    "        if((m % 10)==0):\n",
    "            print(u)\n",
    "        for v in graph_cur[u]:\n",
    "            s=0\n",
    "            nbUV=0\n",
    "            nbnotUV=0\n",
    "            for idx,d in enumerate(data_train[:3]):\n",
    "                probas_chapiteau = getProbaOfList(getListPrec(d),graph_cur)\n",
    "                if(existLinkUV(d,u,v)):\n",
    "                    nbUV+=1\n",
    "                    s+=graph_cur[u][v]*1.0/probas_chapiteau[v]\n",
    "                else:\n",
    "                    nbnotUV+=1\n",
    "            graph_cur[u][v]= s*1.0/(nbUV+nbnotUV) # met a jour les poids\n",
    "                \n",
    "\n",
    "    return graph_cur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#pc = fitModele(data_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#devrait fonctionner\n",
    "def fitModele2(data_train,nbIt=2,eps=1e-1):\n",
    "    succs_train = []\n",
    "    for line in data_train:\n",
    "        succs_train.append(getSuccsOfTab(line))\n",
    "    graph_train = getGraph(succs_train)   \n",
    "        \n",
    "    #init    \n",
    "    theta_cur = getGraphWeightRandom(graph_train)\n",
    "    \n",
    "    for it in range(nbIt):\n",
    "        dicoAS = constructAlldicosSucc(data_train)      \n",
    "        dicoAP = constructAlldicosPrec(data_train)\n",
    "        sommeDico={}\n",
    "        compteurDuvplus={}\n",
    "        compteurDuvmoins={}\n",
    "        for u in theta_cur:\n",
    "            sommeDico[u]={}\n",
    "            compteurDuvplus[u]={}\n",
    "            compteurDuvmoins[u]={}\n",
    "            for v in theta_cur[u]:\n",
    "                sommeDico[u][v]=0.0\n",
    "                compteurDuvplus[u][v]=0.0\n",
    "                compteurDuvmoins[u][v]=0.0\n",
    "        probas=[]\n",
    "        for i in dicoAP:\n",
    "            probas.append(getProbaOfDicoPrec(i,theta_cur))\n",
    "\n",
    "        #A OPTIMISER  \n",
    "        for p in probas:\n",
    "            for u in theta_cur:\n",
    "                for v in theta_cur[u]:\n",
    "                    try:\n",
    "                        p[v]\n",
    "                        try:\n",
    "                            sommeDico[u][v]=sommeDico[u][v]+(theta_cur[u][v]*1.0/p[v])\n",
    "                            compteurDuvplus[u][v]=compteurDuvplus[u][v]+1\n",
    "                        except ZeroDivisionError:\n",
    "                            pass\n",
    "                    except KeyError:\n",
    "                        compteurDuvmoins[u][v]=compteurDuvmoins[u][v]+1\n",
    "        print(compteurDuvplus[0][1]+compteurDuvmoins[0][1])\n",
    "        #maj des poids du graph\n",
    "        theta_tmp = copy.deepcopy(theta_cur)  \n",
    "        for u in theta_tmp:\n",
    "            for v in theta_tmp[u]:\n",
    "                try:\n",
    "                    theta_tmp[u][v]= sommeDico[u][v]*1.0/(compteurDuvplus[u][v]+compteurDuvmoins[u][v])\n",
    "                except ZeroDivisionError:\n",
    "                    pass\n",
    "        \n",
    "        #calcul de la vraissemblance\n",
    "        probas_chap=[]\n",
    "        for i in dicoAP:\n",
    "            probas_chap.append(getProbaOfDicoPrec(i,theta_tmp))  \n",
    "        \n",
    "        vraissemblance=0\n",
    "        for idx,p in enumerate(probas_chap):\n",
    "            for u in theta_tmp:\n",
    "                for v in theta_tmp[u]:\n",
    "                    try:\n",
    "                        p[v]\n",
    "                        try:\n",
    "                            a=(theta_tmp[u][v]/p[v])*np.log(theta_cur[u][v])\n",
    "                            b=(1-theta_tmp[u][v]/p[v])*np.log(1-theta_cur[u][v])\n",
    "                            vraissemblance+= a+b + np.log(1-theta_cur[u][v])\n",
    "                            \n",
    "                        except ZeroDivisionError:\n",
    "                            pass\n",
    "                    except KeyError:\n",
    "                        pass\n",
    "        print(\"vraissemblance\",vraissemblance)\n",
    "        \n",
    "        theta_cur=copy.deepcopy(theta_tmp)\n",
    "    return theta_cur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pc = fitModele2(data_train,nbIt=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inférence\n",
    "Il s'agit à partir du graphe et d'une liste des premiers utilisateurs inféctés, de déduire quels seront les suivants."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[37.0, 11.0, 54.0, 3.0, 68.0, 4.0, 50.0, 12.0, 30.0, 55.0, 8.0, 29.0, 34.0, 89.0, 67.0, 73.0, 82.0, 57.0, 5.0, 99.0, 9.0, 75.0, 84.0, 70.0, 98.0, 90.0, 20.0, 48.0, 61.0, 96.0, 58.0, 43.0, 52.0]\n"
     ]
    }
   ],
   "source": [
    "#ne fonctionne pas\n",
    "def inference(listeT1, graph):\n",
    "    listeUP=[]\n",
    "    listeU=[]\n",
    "    listeTmp=[]\n",
    "    \n",
    "    for u in listeT1:\n",
    "        for v in graph[u]:\n",
    "            if (np.random.rand()<graph[u][v]):\n",
    "                if(v not in listeU):\n",
    "                    listeU.append(v)\n",
    "                    listeUP.append((v,graph[u][v]))\n",
    "                    listeTmp.append(v)\n",
    "                    \n",
    "    t=1\n",
    "    while((len(listeTmp)>0) &(t<15)):\n",
    "        listeTmp2=[]\n",
    "        for u in listeTmp:\n",
    "            for v in graph[u]:\n",
    "                if (np.random.rand()<graph[u][v]):\n",
    "                    if(v not in listeU):\n",
    "                        listeU.append(v)\n",
    "                        listeUP.append((v,graph[u][v]))\n",
    "                        listeTmp2.append(v)\n",
    "        listeTmp=copy.deepcopy(listeTmp2)\n",
    "        t+=1\n",
    "        \n",
    "    listeUP.sort(key=lambda elem: elem[1])\n",
    "    return  [i[0] for i in listeUP]\n",
    "\n",
    "t1=[68.0]\n",
    "print(inference(t1,pc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#devrait fonctionner\n",
    "def inference2(listeT1, graph,iteration):\n",
    "    \n",
    "    dicoProbaInfection={}\n",
    "    for u in graph:\n",
    "        dicoProbaInfection[u]=0\n",
    "        \n",
    "    for it in range(iteration):\n",
    "        listeFinalInfected={}\n",
    "        listeTM1={}\n",
    "        \n",
    "        #on affecte les personnes au temps T2\n",
    "        for u in listeT1.keys():\n",
    "            for v in graph[u]:\n",
    "                if(np.random.rand()<graph[u][v]):\n",
    "                    try:\n",
    "                        listeT1[v]\n",
    "                    except KeyError:\n",
    "                        try:\n",
    "                            listeFinalInfected[v]\n",
    "                            #listeTM1[v]\n",
    "                        except KeyError:\n",
    "                            listeFinalInfected[v]=1\n",
    "                            listeTM1[v]=1\n",
    "        \n",
    "        #on affecte les gens aux temps t3 et suivants\n",
    "        t=1\n",
    "        while(len(listeTM1.keys())>0 & t<20):\n",
    "            listeTM1tmp={}\n",
    "            for u in listeTM1.keys():\n",
    "                for v in graph[u]:\n",
    "                    try:\n",
    "                        listeT1[v]\n",
    "                    except KeyError:\n",
    "                        try:\n",
    "                            listeTM1[v]\n",
    "                        except KeyError: \n",
    "                            try:\n",
    "                                listeFinalInfected[v]\n",
    "                                #listeTM1tmp[v]\n",
    "                            except KeyError:\n",
    "                                try:\n",
    "                                    if (np.random.rand()<graph[u][v]):\n",
    "                                        listeTM1tmp[v]=1\n",
    "                                        listeFinalInfected[v]=1\n",
    "                                except KeyError:\n",
    "                                    print(\"le lien entre u \",u,\"et v \",v,\" n'existe pas dans le graphe\")\n",
    "                        \n",
    "                           \n",
    "            listeTM1=copy.deepcopy(listeTM1tmp)\n",
    "            t+=1\n",
    "            \n",
    "        for u in listeFinalInfected:\n",
    "            dicoProbaInfection[u]+=1\n",
    "\n",
    "    somme = 0\n",
    "    for u in dicoProbaInfection:\n",
    "        somme += dicoProbaInfection[u]\n",
    "        \n",
    "    for u in dicoProbaInfection:\n",
    "        try:\n",
    "            dicoProbaInfection[u] = dicoProbaInfection[u]*1.0/somme\n",
    "        except ZeroDivisionError:\n",
    "            pass\n",
    "    return  dicoProbaInfection\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# La mean average precision\n",
    "\n",
    "Elle permet d'évaluer notre modèle de diffusion en calculant la précision moyenne entre la liste de diffusion réelle et celle prédite par notre algorithme."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def MAP(graph,data_test):\n",
    "    s=0\n",
    "    for d in data_test:\n",
    "        listeD=[i[0] for i in d if (i[1]>1)]\n",
    "        listeT1=[i[0] for i in d if (i[1]==1)]\n",
    "        listeU=inference(listeT1,graph)\n",
    "        s2=0\n",
    "        for i,u in enumerate(listeU):\n",
    "            intersection = [val for val in listeD if val in listeU[:i]]\n",
    "            s2+=len(intersection)*1.0/(i+1)\n",
    "        try:\n",
    "            s+=s2/len(listeU)\n",
    "        except ZeroDivisionError:\n",
    "            pass\n",
    "    return s/len(data_test)\n",
    "MAP(pc,data_test)     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "MAP2(pc,data_test)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#devrait fonctionner\n",
    "def MAP2(graph,data_test,it=2):\n",
    "    s=0\n",
    "    for d in tqdm(data_test):#boucle dataset\n",
    "        \n",
    "        listeD=[i[0] for i in d if (i[1]>1)]\n",
    "        listeT1={}\n",
    "        for i in d:\n",
    "            if (i[1]==1):\n",
    "                 listeT1[i[0]]=1     \n",
    "        dicoU=inference2(listeT1,graph,it)\n",
    "        listeU = [i[0] for i in sorted(dicoU.items(), key=operator.itemgetter(1))[::-1]]\n",
    "        \n",
    "        s2=0\n",
    "        for i,u in enumerate(listeU):\n",
    "            intersection = [val for val in listeD if val in listeU[:i]]\n",
    "            s2+=len(intersection)*1.0/(i+1)\n",
    "        try:\n",
    "            s+=s2/len(listeU)\n",
    "        except ZeroDivisionError:\n",
    "            pass\n",
    "    return s/len(data_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "data": {
      "text/plain": [
       "0.13164138039898668"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MAP2(pc,data_test)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Optimisation de IC avec spark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lors de l'apprentissage de l'algorithme IC, nous faisons trois boucles:\n",
    "\n",
    "** - une pour chaque episode**\n",
    "\n",
    "** - une pour chaque utilisateur u qui est infecté**\n",
    "\n",
    "** - une pour chaque utilisateur v qui est suceptible d'être infecté**\n",
    "\n",
    "Nous proposons de faire correspondre à la liste des épisode, une structure RDD permettant d'être \"mappée\". Le résultat de ce map renverra trois liste de tuples (key,value) ayant chacun pour key un tuple (u,v).\n",
    "\n",
    "**premier tuple :** ((u,v),value) avec $value =\\tfrac{\\hat{\\Theta}_{u,v}}{\\hat{P}_{t_{v^D}}(v)}$ ##nous l'appelerons X\n",
    "\n",
    "**deuxième tuple:** ((u,v),value) avec $value = 1$ quand $D_{u,v}+$ existe 0 sinon ##nous l'appelerons A\n",
    "\n",
    "**troisième tuple:** ((u,v),value) avec $value = 1$ quand $D_{u,v}-$ existe 0 sinon ##nous l'appelerons B\n",
    "\n",
    "Il reste à faire l'opération de reduce sur ces trois liste de tuples qui fait l'addition entre chaque pair de meme key. Il reste à map toutes les key (u,v) possible et de faire l'opération voulu c'est a dire \n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
