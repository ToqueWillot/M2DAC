{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from random import random\n",
    "\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collect data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def loadMovieLens(path='./data/movielens'):\n",
    "    #Get movie titles\n",
    "    movies={}\n",
    "    for line in open(path+'/u.item'):\n",
    "        id,title=line.split('|')[0:2]\n",
    "        movies[id]=title\n",
    "\n",
    "    # Load data\n",
    "    prefs={}\n",
    "    for line in open(path+'/u.data'):\n",
    "        (user,movieid,rating,ts)=line.split('\\t')\n",
    "        prefs.setdefault(user,{})\n",
    "        prefs[user][movies[movieid]]=float(rating)\n",
    "        \n",
    "    return prefs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = loadMovieLens(\"data/ml-100k\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'187 (1997)': 2.0,\n",
       " 'Air Force One (1997)': 2.0,\n",
       " 'Alien: Resurrection (1997)': 3.0,\n",
       " 'Apostle, The (1997)': 4.0,\n",
       " 'Bean (1997)': 2.0,\n",
       " 'Boogie Nights (1997)': 5.0,\n",
       " 'Chasing Amy (1997)': 3.0,\n",
       " 'Conspiracy Theory (1997)': 5.0,\n",
       " 'Contact (1997)': 2.0,\n",
       " 'Cop Land (1997)': 4.0,\n",
       " 'Crash (1996)': 1.0,\n",
       " 'Critical Care (1997)': 1.0,\n",
       " \"Dante's Peak (1997)\": 2.0,\n",
       " 'Deconstructing Harry (1997)': 3.0,\n",
       " 'Deep Rising (1998)': 1.0,\n",
       " 'Desperate Measures (1998)': 4.0,\n",
       " \"Devil's Advocate, The (1997)\": 3.0,\n",
       " \"Devil's Own, The (1997)\": 1.0,\n",
       " 'Edge, The (1997)': 4.0,\n",
       " 'Event Horizon (1997)': 4.0,\n",
       " 'Everyone Says I Love You (1996)': 2.0,\n",
       " 'Fallen (1998)': 3.0,\n",
       " 'G.I. Jane (1997)': 2.0,\n",
       " 'Game, The (1997)': 2.0,\n",
       " 'Good Will Hunting (1997)': 2.0,\n",
       " 'Hard Rain (1998)': 3.0,\n",
       " 'Hoodlum (1997)': 3.0,\n",
       " 'House of Yes, The (1997)': 1.0,\n",
       " 'How to Be a Player (1997)': 1.0,\n",
       " 'In the Name of the Father (1993)': 2.0,\n",
       " 'Jackie Brown (1997)': 5.0,\n",
       " 'Kiss the Girls (1997)': 1.0,\n",
       " 'L.A. Confidential (1997)': 2.0,\n",
       " 'Liar Liar (1997)': 2.0,\n",
       " 'Lost Highway (1997)': 2.0,\n",
       " 'Mad City (1997)': 3.0,\n",
       " 'Man Who Knew Too Little, The (1997)': 4.0,\n",
       " 'Mimic (1997)': 2.0,\n",
       " 'Mother (1996)': 5.0,\n",
       " 'Murder at 1600 (1997)': 3.0,\n",
       " 'Paradise Lost: The Child Murders at Robin Hood Hills (1996)': 5.0,\n",
       " 'Playing God (1997)': 1.0,\n",
       " 'Prophecy II, The (1998)': 3.0,\n",
       " 'Return of the Jedi (1983)': 4.0,\n",
       " \"Schindler's List (1993)\": 4.0,\n",
       " 'Scream (1996)': 2.0,\n",
       " 'Sphere (1998)': 3.0,\n",
       " 'Spice World (1997)': 2.0,\n",
       " 'Starship Troopers (1997)': 3.0,\n",
       " 'U Turn (1997)': 3.0,\n",
       " \"Ulee's Gold (1997)\": 3.0,\n",
       " 'Wag the Dog (1997)': 5.0,\n",
       " 'Wedding Singer, The (1998)': 3.0}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['3']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creation of train set and test set\n",
    "We want to split data in two set (train and test)\n",
    "\n",
    "Actually : \n",
    "\n",
    " ** train= 80%totaldataset**\n",
    " \n",
    " ** test = 20%totaldataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def split_train_test(data,percent_test):\n",
    "    test={}\n",
    "    train={}\n",
    "    movie={}\n",
    "    for u in data.keys():\n",
    "        test.setdefault(u,{})\n",
    "        train.setdefault(u,{})\n",
    "        for movie in data[u]:\n",
    "            #print(data[u][movie])\n",
    "            if (random()<percent_test):\n",
    "                test[u][movie]=data[u][movie]\n",
    "            else:\n",
    "                train[u][movie]=data[u][movie]\n",
    "    return train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "percent_test=0.2\n",
    "train,test=split_train_test(data,percent_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part that allows to clean train and test\n",
    "We don't want to have user in test set which are not in train test, the same for the movies so we delete them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_moove(data):\n",
    "    moove = {}\n",
    "    for u in data:\n",
    "        for m in data[u]:\n",
    "            moove[m]=0\n",
    "    return moove\n",
    "            \n",
    "def get_youser(data):\n",
    "    youser = {}\n",
    "    for u in data:\n",
    "        youser[u]=0\n",
    "    return youser  \n",
    "\n",
    "def clean(d1,d2):\n",
    "    to_erase = {}\n",
    "    for i in d1:\n",
    "        try:\n",
    "            d2[i]\n",
    "        except KeyError:\n",
    "            to_erase[i]=0\n",
    "    for i in d2:\n",
    "        try:\n",
    "            d1[i]\n",
    "        except KeyError:\n",
    "            to_erase[i]=0\n",
    "    return to_erase\n",
    "def _remove_users(test,rem):\n",
    "    for i in rem:\n",
    "        try:\n",
    "            del test[i]\n",
    "        except KeyError:\n",
    "            pass\n",
    "def _remove_movies(test,rem):\n",
    "    for i in test:\n",
    "        for j in rem:\n",
    "            try:\n",
    "                del test[i][j]\n",
    "            except KeyError:\n",
    "                pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mooveToRemoove = clean(get_moove(train),get_moove(test))\n",
    "youserToRemoove = clean(get_youser(train),get_youser(test))\n",
    "_remove_users(test,youserToRemoove)\n",
    "_remove_movies(test,mooveToRemoove)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collaboritive Filtering classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class BaselineMeanUser:\n",
    "    def __init__(self):\n",
    "        self.users={}\n",
    "        self.movies={}\n",
    "    def fit(self,train):\n",
    "        for user in train:\n",
    "            note=0\n",
    "            for movie in train[user]:\n",
    "                note+=train[user][movie]\n",
    "            note=note/len(train[user])\n",
    "            self.users[user]=note\n",
    "        \n",
    "    def predict(self,user,movie):\n",
    "        return self.users[user]\n",
    "    def score(self,X):\n",
    "        nb_movies = len(get_moove(X))\n",
    "        score = 0.0\n",
    "        for user in X:\n",
    "            for movie in X[user]:\n",
    "                score += (self.predict(user,movie) - X[user][movie])**2\n",
    "        return score/nb_movies\n",
    "                \n",
    "                    \n",
    "    \n",
    "class BaselineMeanMovie:\n",
    "    def __init__(self):\n",
    "        self.users={}\n",
    "        self.movies={}\n",
    "    def fit(self,train):\n",
    "        movies = get_moove(train)\n",
    "        for movie in movies:\n",
    "            note=0\n",
    "            cpt=0\n",
    "            for user in train:\n",
    "                try:\n",
    "                    note+=train[user][movie]\n",
    "                    cpt+=1\n",
    "                except KeyError:\n",
    "                    pass\n",
    "            note=note/cpt\n",
    "            self.movies[movie]=note\n",
    "        \n",
    "    def predict(self,user,movie):\n",
    "        return self.movies[movie]\n",
    "    def score(self,X):\n",
    "        nb_movies = len(get_moove(X))\n",
    "        score = 0.0\n",
    "        for user in X:\n",
    "            for movie in X[user]:\n",
    "                score += (self.predict(user,movie) - X[user][movie])**2\n",
    "        return score/nb_movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "baseline_mu= BaselineMeanUser()\n",
    "baseline_mm= BaselineMeanMovie()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "baseline_mu.fit(train)\n",
    "baseline_mm.fit(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('score baseline mean user  ', 15.993894035341953)\n",
      "('score baseline mean movie ', 15.254203103208283)\n"
     ]
    }
   ],
   "source": [
    "print(\"score baseline mean user  \",baseline_mu.score(test))\n",
    "print(\"score baseline mean movie \",baseline_mm.score(test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# NMF by alternative non-negative least squares using projected gradients\n",
    "# Author: Chih-Jen Lin, National Taiwan University\n",
    "# Python/numpy translation: Anthony Di Franco\n",
    "\n",
    "from numpy import *\n",
    "from numpy.linalg import norm\n",
    "from time import time\n",
    "from sys import stdout\n",
    "\n",
    "def nmf(V,Winit,Hinit,tol,timelimit,maxiter):\n",
    "    \"\"\"\n",
    "    (W,H) = nmf(V,Winit,Hinit,tol,timelimit,maxiter)\n",
    "    W,H: output solution\n",
    "    Winit,Hinit: initial solution\n",
    "    tol: tolerance for a relative stopping condition\n",
    "    timelimit, maxiter: limit of time and iterations\n",
    "    \"\"\"\n",
    "\n",
    "    W = Winit; H = Hinit; initt = time();\n",
    "\n",
    "    gradW = dot(W, dot(H, H.T)) - dot(V, H.T)\n",
    "    gradH = dot(dot(W.T, W), H) - dot(W.T, V)\n",
    "    initgrad = norm(r_[gradW, gradH.T])\n",
    "    print 'Init gradient norm %f' % initgrad \n",
    "    tolW = max(0.001,tol)*initgrad\n",
    "    tolH = tolW\n",
    "\n",
    "    for iter in xrange(1,maxiter):\n",
    "        # stopping condition\n",
    "        projnorm = norm(r_[gradW[logical_or(gradW<0, W>0)],\n",
    "                                     gradH[logical_or(gradH<0, H>0)]])\n",
    "        if projnorm < tol*initgrad or time() - initt > timelimit: break\n",
    "\n",
    "        (W, gradW, iterW) = nlssubprob(V.T,H.T,W.T,tolW,1000)\n",
    "        W = W.T\n",
    "        gradW = gradW.T\n",
    "\n",
    "        if iterW==1: tolW = 0.1 * tolW\n",
    "\n",
    "        (H,gradH,iterH) = nlssubprob(V,W,H,tolH,1000)\n",
    "        if iterH==1: tolH = 0.1 * tolH\n",
    "\n",
    "        if iter % 10 == 0: stdout.write('.')\n",
    "\n",
    "    print '\\nIter = %d Final proj-grad norm %f' % (iter, projnorm)\n",
    "    return (W,H)\n",
    "\n",
    "def nlssubprob(V,W,Hinit,tol,maxiter):\n",
    "    \"\"\"\n",
    "    H, grad: output solution and gradient\n",
    "    iter: #iterations used\n",
    "    V, W: constant matrices\n",
    "    Hinit: initial solution\n",
    "    tol: stopping tolerance\n",
    "    maxiter: limit of iterations\n",
    "    \"\"\"\n",
    "\n",
    "    H = Hinit\n",
    "    WtV = dot(W.T, V)\n",
    "    WtW = dot(W.T, W) \n",
    "\n",
    "    alpha = 1; beta = 0.1;\n",
    "    for iter in xrange(1, maxiter):  \n",
    "        grad = dot(WtW, H) - WtV\n",
    "        projgrad = norm(grad[logical_or(grad < 0, H >0)])\n",
    "        if projgrad < tol: break\n",
    "\n",
    "    # search step size \n",
    "    for inner_iter in xrange(1,20):\n",
    "        Hn = H - alpha*grad\n",
    "        Hn = where(Hn > 0, Hn, 0)\n",
    "        d = Hn-H\n",
    "        gradd = sum(grad * d)\n",
    "        dQd = sum(dot(WtW,d) * d)\n",
    "        suff_decr = 0.99*gradd + 0.5*dQd < 0;\n",
    "        if inner_iter == 1:\n",
    "            decr_alpha = not suff_decr; Hp = H;\n",
    "        if decr_alpha: \n",
    "            if suff_decr:\n",
    "                H = Hn; break;\n",
    "            else:\n",
    "                alpha = alpha * beta;\n",
    "        else:\n",
    "            if not suff_decr or (Hp == Hn).all():\n",
    "                H = Hp; break;\n",
    "            else:\n",
    "                alpha = alpha/beta; Hp = Hn;\n",
    "\n",
    "    if iter == maxiter:\n",
    "        print 'Max iter in nlssubprob'\n",
    "    return (H, grad, iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Init gradient norm 125.475097\n",
      "\n",
      "Iter = 5 Final proj-grad norm 0.119379\n",
      "[[ 0.3904523   0.3904523   0.3904523 ]\n",
      " [ 0.63257492  0.63257492  0.63257492]]\n",
      "[[ 2.46681606  1.52881008]\n",
      " [ 2.46681606  1.52881008]\n",
      " [ 2.46681606  1.52881008]]\n"
     ]
    }
   ],
   "source": [
    "from numpy import *\n",
    "from nmf import *\n",
    "\n",
    "w1 = array([[1,2,3],[4,5,6]])\n",
    "h1 = array([[1,2],[3,4],[5,6]])\n",
    "w2 = array([[1,1,3],[4,5,6]])\n",
    "h2 = array([[1,1],[3,4],[5,6]])\n",
    "w3 = array([[2,2,2],[2,2,2]])\n",
    "h3 = array([[2,2],[2,2],[2,2]])\n",
    "\n",
    "# v the ratings matrix\n",
    "# v = dot(w1,h1)\n",
    "v = array([array([4,0]),array([4,4])])\n",
    "\n",
    "(wo,ho) = nmf(v, w3, h3, 0.001, 10, 10)\n",
    "print wo\n",
    "print ho"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[4 0]\n",
      " [4 4]]\n",
      "[[ 2.88952199  1.79078222]\n",
      " [ 4.68133791  2.90126074]]\n"
     ]
    }
   ],
   "source": [
    "print v\n",
    "print dot(wo,ho)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
