{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TME4 FDMS Collaborative Filtering \n",
    "\n",
    "Florian Toqu√© & Paul Willot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from random import random\n",
    "import math\n",
    "import numpy as np\n",
    "import copy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def loadMovieLens(path='./data/movielens'):\n",
    "    #Get movie titles\n",
    "    movies={}\n",
    "    rev_movies={}\n",
    "    for idx,line in enumerate(open(path+'/u.item')):\n",
    "        idx,title=line.split('|')[0:2]\n",
    "        movies[idx]=title\n",
    "        rev_movies[title]=idx\n",
    "\n",
    "    # Load data\n",
    "    prefs={}\n",
    "    for line in open(path+'/u.data'):\n",
    "        (user,movieid,rating,ts)=line.split('\\t')\n",
    "        prefs.setdefault(user,{})\n",
    "        prefs[user][movies[movieid]]=float(rating)\n",
    "        \n",
    "    return prefs,rev_movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data,movies = loadMovieLens(\"data/ml-100k\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Content example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'187 (1997)': 2.0,\n",
       " 'Air Force One (1997)': 2.0,\n",
       " 'Alien: Resurrection (1997)': 3.0,\n",
       " 'Apostle, The (1997)': 4.0,\n",
       " 'Bean (1997)': 2.0,\n",
       " 'Boogie Nights (1997)': 5.0,\n",
       " 'Chasing Amy (1997)': 3.0,\n",
       " 'Conspiracy Theory (1997)': 5.0,\n",
       " 'Contact (1997)': 2.0,\n",
       " 'Cop Land (1997)': 4.0,\n",
       " 'Crash (1996)': 1.0,\n",
       " 'Critical Care (1997)': 1.0,\n",
       " \"Dante's Peak (1997)\": 2.0,\n",
       " 'Deconstructing Harry (1997)': 3.0,\n",
       " 'Deep Rising (1998)': 1.0,\n",
       " 'Desperate Measures (1998)': 4.0,\n",
       " \"Devil's Advocate, The (1997)\": 3.0,\n",
       " \"Devil's Own, The (1997)\": 1.0,\n",
       " 'Edge, The (1997)': 4.0,\n",
       " 'Event Horizon (1997)': 4.0,\n",
       " 'Everyone Says I Love You (1996)': 2.0,\n",
       " 'Fallen (1998)': 3.0,\n",
       " 'G.I. Jane (1997)': 2.0,\n",
       " 'Game, The (1997)': 2.0,\n",
       " 'Good Will Hunting (1997)': 2.0,\n",
       " 'Hard Rain (1998)': 3.0,\n",
       " 'Hoodlum (1997)': 3.0,\n",
       " 'House of Yes, The (1997)': 1.0,\n",
       " 'How to Be a Player (1997)': 1.0,\n",
       " 'In the Name of the Father (1993)': 2.0,\n",
       " 'Jackie Brown (1997)': 5.0,\n",
       " 'Kiss the Girls (1997)': 1.0,\n",
       " 'L.A. Confidential (1997)': 2.0,\n",
       " 'Liar Liar (1997)': 2.0,\n",
       " 'Lost Highway (1997)': 2.0,\n",
       " 'Mad City (1997)': 3.0,\n",
       " 'Man Who Knew Too Little, The (1997)': 4.0,\n",
       " 'Mimic (1997)': 2.0,\n",
       " 'Mother (1996)': 5.0,\n",
       " 'Murder at 1600 (1997)': 3.0,\n",
       " 'Paradise Lost: The Child Murders at Robin Hood Hills (1996)': 5.0,\n",
       " 'Playing God (1997)': 1.0,\n",
       " 'Prophecy II, The (1998)': 3.0,\n",
       " 'Return of the Jedi (1983)': 4.0,\n",
       " \"Schindler's List (1993)\": 4.0,\n",
       " 'Scream (1996)': 2.0,\n",
       " 'Sphere (1998)': 3.0,\n",
       " 'Spice World (1997)': 2.0,\n",
       " 'Starship Troopers (1997)': 3.0,\n",
       " 'U Turn (1997)': 3.0,\n",
       " \"Ulee's Gold (1997)\": 3.0,\n",
       " 'Wag the Dog (1997)': 5.0,\n",
       " 'Wedding Singer, The (1998)': 3.0}"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['3']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting data between train/test  \n",
    "\n",
    "We avoid to let unseen data form the train set in the test set.  \n",
    "We also try to minimise the dataset reduction by splitting on each user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getRawArray(data):\n",
    "    d = []\n",
    "    for u in data.keys():\n",
    "        for i in data[u].keys():\n",
    "            d.append([u,i,data[u][i]])\n",
    "    return np.array(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# splitting while avoiding to reduce the dataset too much\n",
    "def split_train_test(data,percent_test):\n",
    "    test={}\n",
    "    train={}\n",
    "    movie={}\n",
    "    for u in data.keys():\n",
    "        test.setdefault(u,{})\n",
    "        train.setdefault(u,{})\n",
    "        for movie in data[u]:\n",
    "            #print(data[u][movie])\n",
    "            if (random()<percent_test):\n",
    "                test[u][movie]=data[u][movie]\n",
    "            else:\n",
    "                train[u][movie]=data[u][movie]\n",
    "    return train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def split_train_test_by_movies(data,percent_test):\n",
    "    test={}\n",
    "    train={}\n",
    "    movie={}\n",
    "    for u in data.keys():\n",
    "        for movie in data[u]:\n",
    "            if (random()<percent_test):\n",
    "                try:\n",
    "                    test[movie][u]=data[u][movie]\n",
    "                except KeyError:\n",
    "                    test.setdefault(movie,{})\n",
    "                    test[movie][u]=data[u][movie]\n",
    "            else:\n",
    "                try:\n",
    "                    train[movie][u]=data[u][movie]\n",
    "                except KeyError:\n",
    "                    train.setdefault(movie,{})\n",
    "                    train[movie][u]=data[u][movie]\n",
    "    return train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "percent_test=0.2\n",
    "train,test=split_train_test(data,percent_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_split used for convenience on the average by movie baseline_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "percent_test=0.2\n",
    "m_train,m_test=split_train_test_by_movies(data,percent_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_cleaning_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def deleteUnseenInTest(train,test):\n",
    "    for k in test.keys():\n",
    "        try:\n",
    "            train[k]\n",
    "        except KeyError:\n",
    "            test.pop(k,None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "deleteUnseenInTest(train,test)\n",
    "deleteUnseenInTest(m_train,m_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Matrix used for fast evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "evalArrayAll = getRawArray(data)\n",
    "evalArrayTest = getRawArray(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['344', 'Ransom (1996)', '3.0'],\n",
       "       ['344', 'Strictly Ballroom (1992)', '5.0'],\n",
       "       ['344', 'Mars Attacks! (1996)', '3.0'],\n",
       "       ['344', 'Twister (1996)', '3.0'],\n",
       "       ['344', 'People vs. Larry Flynt, The (1996)', '4.0'],\n",
       "       ['344', 'Out to Sea (1997)', '2.0'],\n",
       "       ['344', 'Sabrina (1954)', '4.0'],\n",
       "       ['344', 'Secrets & Lies (1996)', '5.0'],\n",
       "       ['344', 'Copycat (1995)', '3.0'],\n",
       "       ['344', \"Smilla's Sense of Snow (1997)\", '3.0']], \n",
       "      dtype='|S79')"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evalArrayTest[:10,:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline: mean by user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class baselineMeanUser:\n",
    "    def __init__(self):\n",
    "        self.users={}\n",
    "    def fit(self,train):\n",
    "        for user in train.keys():\n",
    "            note=0.0\n",
    "            for movie in train[user].keys():\n",
    "                note+=train[user][movie]\n",
    "            note=note/len(train[user])\n",
    "            self.users[user]=note\n",
    "        \n",
    "    def predict(self,users):\n",
    "        return [self.users[u] for u in users]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Error 1.064954\n"
     ]
    }
   ],
   "source": [
    "baseline_mu= baselineMeanUser()\n",
    "baseline_mu.fit(train)\n",
    "pred = baseline_mu.predict(evalArrayTest[:,0])\n",
    "print(\"Mean Error %0.6f\" %(\n",
    "        (np.array(pred) - np.array(evalArrayTest[:,2], float)) ** 2).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class baselineMeanMovie:\n",
    "    def __init__(self):\n",
    "        self.movies={}\n",
    "    def fit(self,train):\n",
    "        for movie in train.keys():\n",
    "            note=0.0\n",
    "            for user in train[movie].keys():\n",
    "                note+=train[movie][user]\n",
    "            note=note/len(train[movie])\n",
    "            self.movies[movie]=note\n",
    "        \n",
    "    def predict(self,movies):\n",
    "        res=[]\n",
    "        for m in movies:\n",
    "            try:\n",
    "                res.append(self.movies[m])\n",
    "            except:\n",
    "                res.append(3)\n",
    "        return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Error 0.981749\n"
     ]
    }
   ],
   "source": [
    "baseline_mm= baselineMeanMovie()\n",
    "baseline_mm.fit(m_train)\n",
    "pred = baseline_mm.predict(evalArrayTest[:,1])\n",
    "print(\"Mean Error %0.6f\" %(\n",
    "        (np.array(pred) - np.array(evalArrayTest[:,2], float)) ** 2).mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Raw matrix used for convenience and clarity.  \n",
    "Structure like scipy sparse matrix or python dictionnaries may be used for speedup."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Complete dataset_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rawMatrix = np.zeros((len(data.keys()),1682))\n",
    "for u in data:\n",
    "    for m in data[u]:\n",
    "        rawMatrix[int(u)-1][int(movies[m])-1] = data[u][m]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(943, 1682)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 5.,  3.,  4.,  3.,  3.,  5.,  4.,  1.,  5.,  3.],\n",
       "       [ 4.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  2.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 4.,  3.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 4.,  0.,  0.,  0.,  0.,  0.,  2.,  4.,  4.,  0.],\n",
       "       [ 0.,  0.,  0.,  5.,  0.,  0.,  5.,  5.,  5.,  4.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0.,  3.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  5.,  4.,  0.,  0.,  0.],\n",
       "       [ 4.,  0.,  0.,  4.,  0.,  0.,  4.,  0.,  4.,  0.]])"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(np.shape(rawMatrix))\n",
    "rawMatrix[:10,:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Train and test dataset_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rawMatrixTrain = np.zeros((len(data.keys()),1682))\n",
    "for u in train:\n",
    "    for m in train[u]:\n",
    "        rawMatrixTrain[int(u)-1][int(movies[m])-1] = train[u][m]\n",
    "        \n",
    "rawMatrixTest = np.zeros((len(data.keys()),1682))\n",
    "for u in test:\n",
    "    for m in test[u]:\n",
    "        rawMatrixTest[int(u)-1][int(movies[m])-1] = test[u][m]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## [Non-negative Matrix Factorization](https://en.wikipedia.org/wiki/Non-negative_matrix_factorization)\n",
    "\n",
    "Fast implementation using numpy's matrix processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#from scipy import linalg\n",
    "\n",
    "def nmf(X, latent_features, max_iter=100, eps = 1e-5,printevery=100):\n",
    "\n",
    "    print \"NMF with %d latent features, %d iterations.\"%(latent_features, max_iter)\n",
    "\n",
    "    # mask used to ignore null element (coded by zero)\n",
    "    mask = np.sign(X)\n",
    "\n",
    "    # randomly initialized matrix\n",
    "    rows, columns = X.shape\n",
    "    A = np.random.rand(rows, latent_features)\n",
    "    \n",
    "    Y = np.random.rand(latent_features, columns)\n",
    "    # Not used as I couldn't find significant improvments\n",
    "    #Y = linalg.lstsq(A, X)[0]  # initializing that way as recommanded in a blog post\n",
    "    #Y = np.maximum(Y, eps)     # avoiding too low values\n",
    "\n",
    "    masked_X = mask * X\n",
    "    masktest = np.sign(rawMatrixTest)    # used for prints\n",
    "    masktrain = np.sign(rawMatrixTrain)  # used for prints\n",
    "\n",
    "    for i in range(1, max_iter + 1):\n",
    "\n",
    "        top = np.dot(masked_X, Y.T)\n",
    "        bottom = (np.dot((mask * np.dot(A, Y)), Y.T)) + eps\n",
    "        A *= top / bottom\n",
    "        \n",
    "        top = np.dot(A.T, masked_X)\n",
    "        bottom = np.dot(A.T, mask * np.dot(A, Y)) + eps\n",
    "        Y *= top / bottom\n",
    "\n",
    "\n",
    "        # evaluation\n",
    "        if i % printevery == 0 or i == 1 or i == max_iter:\n",
    "            X_est = np.dot(A, Y)\n",
    "            q = masktest*X_est - rawMatrixTest\n",
    "            q_train = masktrain*X_est - rawMatrixTrain\n",
    "            print \"Iteration %d, Err %.05f, Err train %.05f\"%( i, (q*q).sum()/ masktest.sum(), (q_train*q_train).sum()/ masktest.sum() )\n",
    "            \n",
    "    return A, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NMF with 100 latent features, 5 iterations.\n",
      "Iteration 1, Err 0.92854, Err train 3.48107\n",
      "Iteration 2, Err 0.89742, Err train 3.29107\n",
      "Iteration 3, Err 0.89667, Err train 3.22399\n",
      "Iteration 4, Err 0.89701, Err train 3.16422\n",
      "Iteration 5, Err 0.89745, Err train 3.10647\n",
      "CPU times: user 984 ms, sys: 118 ms, total: 1.1 s\n",
      "Wall time: 617 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "A,Y = nmf(rawMatrixTrain,100,eps = 1e-5,max_iter=5,printevery=1)\n",
    "resMatrix = A.dot(Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that it quickly get **better than the baseline**.  \n",
    "However, we see below that it **overfit** after that:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NMF with 100 latent features, 500 iterations.\n",
      "Iteration 1, Err 0.93665, Err train 3.52000\n",
      "Iteration 100, Err 1.19580, Err train 0.55700\n",
      "Iteration 200, Err 1.38603, Err train 0.28243\n",
      "Iteration 300, Err 1.49323, Err train 0.19640\n",
      "Iteration 400, Err 1.56915, Err train 0.15397\n",
      "Iteration 500, Err 1.62885, Err train 0.12858\n",
      "CPU times: user 1min 9s, sys: 3.95 s, total: 1min 13s\n",
      "Wall time: 31.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "A,Y = nmf(rawMatrixTrain,100,eps = 1e-5,max_iter=500,printevery=100)\n",
    "resMatrix = A.dot(Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is due to the high sparsity of the matrix.  \n",
    "We can of course reduce the features matrix size to avoid overfitting, but that will limit further improvments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NMF with 1 latent features, 100 iterations.\n",
      "Iteration 1, Err 0.93438, Err train 3.57343\n",
      "Iteration 20, Err 0.88116, Err train 3.36634\n",
      "Iteration 40, Err 0.88116, Err train 3.36634\n",
      "Iteration 60, Err 0.88116, Err train 3.36634\n",
      "Iteration 80, Err 0.88116, Err train 3.36634\n",
      "Iteration 100, Err 0.88116, Err train 3.36634\n",
      "CPU times: user 3.34 s, sys: 738 ms, total: 4.07 s\n",
      "Wall time: 2.98 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "A,Y = nmf(rawMatrixTrain,1,eps = 1e-5,max_iter=100,printevery=20)\n",
    "resMatrix = A.dot(Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Despite good results in few seconds on this dataset, this can only get us so far.  \n",
    "_We then have to add regularization to the cost function._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## This class is used to make predictions\n",
    "class evalMF:\n",
    "    def __init__(self,resMatrix,dicU,dicI):\n",
    "        self.resMatrix=resMatrix\n",
    "        self.dicU = dicU\n",
    "        self.dicI = dicI\n",
    "    def fit(self):\n",
    "        pass\n",
    "        \n",
    "    def predict(self,user,movie):\n",
    "        return self.resMatrix[int(user)-1][int(self.dicI[movie])-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mf = evalMF(resMatrix,data,movies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.89275690554990295"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# np.array([ (float(ra[2]) - mf.predict(ra[0],ra[1]))**2 for ra in evalArrayTest]).mean()\n",
    "# faster evaluation\n",
    "masqueTest=np.sign(rawMatrixTest)\n",
    "q = masqueTest*resMatrix - rawMatrixTest\n",
    "(q*q).sum()/ masqueTest.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.0\n",
      "3.66336132148\n",
      "3.0\n",
      "3.32141384965\n"
     ]
    }
   ],
   "source": [
    "print data[\"1\"][\"Akira (1988)\"]\n",
    "print mf.predict(\"1\",\"Akira (1988)\")\n",
    "print data[\"1\"][\"I.Q. (1994)\"]\n",
    "print mf.predict(\"1\",\"I.Q. (1994)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We usualy see an important difference between users, so we need to take the bias into account."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.95019735270796091"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summ=0\n",
    "for i in data[\"1\"]:\n",
    "    summ+=(float(data[\"1\"][i]) - mf.predict(\"1\",i))**2\n",
    "summ/len(data[\"1\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.3200645835765501"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summ=0\n",
    "for i in data[\"3\"]:\n",
    "    summ+=(float(data[\"3\"][i]) - mf.predict(\"3\",i))**2\n",
    "summ/len(data[\"3\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---  \n",
    "\n",
    "Various atempts to incoporate the **bias** and the **L1 regularization** can be found below.  \n",
    "**However, we have not been very successful with them yet...**  \n",
    "A simpler yet slower model can be found at the bottom of the page, in which the bias and L1 regularization can be added easly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#self.lamb*np.linalg.norm(self.theta)\n",
    "\n",
    "#from scipy import linalg\n",
    "\n",
    "def nmf(X, latent_features, max_iter=100, eps = 1e-5, printevery=100):\n",
    "\n",
    "    print \"NMF with %d latent features, %d iterations.\"%(latent_features, max_iter)\n",
    "    \n",
    "    #lamb = 0.2\n",
    "    \n",
    "\n",
    "    ## User and Item bais\n",
    "    \n",
    "    #X = copy.deepcopy(rawMatrix)\n",
    "    #with np.errstate(all='ignore'):\n",
    "    #avg_m = X.sum(0)/(X != 0).sum(0)\n",
    "    #avg_u = X.sum(1)/(X != 0).sum(1)\n",
    "    #diff_m = avg_m - avg_m.mean()\n",
    "    #diff_u = avg_u - avg_u.mean()\n",
    "    #print(avg_u.mean())\n",
    "    #X = X - diff_m\n",
    "    #for idxi,i in enumerate(X):\n",
    "    #    for idxj,j in enumerate(i):\n",
    "    #        if X[idxi,idxj]!=0:\n",
    "    #            X[idxi,idxj]+=diff_u[idxi]\n",
    "\n",
    "    mask = np.sign(X)\n",
    "\n",
    "    rows, columns = X.shape\n",
    "    A = np.random.rand(rows, latent_features)\n",
    "    \n",
    "    Y = np.random.rand(latent_features, columns)\n",
    "    # Not used as I couldn't find significant improvments\n",
    "    #Y = linalg.lstsq(A, X)[0]  # initializing that way as recommanded in a blog post\n",
    "    #Y = np.maximum(Y, eps)     # avoiding too low values\n",
    "\n",
    "    masked_X = mask * X\n",
    "    masktest = np.sign(rawMatrixTest)    # used for prints\n",
    "    masktrain = np.sign(rawMatrixTrain)  # used for prints\n",
    "    \n",
    "    prev_A = A\n",
    "    prev_Y = Y\n",
    "    \n",
    "\n",
    "    \n",
    "\n",
    "    #diff_u = (avg_u - avg_u.mean().T).T\n",
    "    #(np.array([1,5])-mat.T).T\n",
    "    \n",
    "\n",
    "    for i in range(1, max_iter + 1):\n",
    "\n",
    "        top = np.dot(masked_X, Y.T)\n",
    "        esti = np.dot((mask * np.dot(A, Y)), Y.T)\n",
    "        #esti = esti - diff_u\n",
    "        bottom = esti + eps\n",
    "        #print(\"val\",np.shape(top/bottom))\n",
    "        A *= top / bottom\n",
    "        \n",
    "        top = np.dot(A.T, masked_X)\n",
    "        esti = np.dot(A.T, mask * np.dot(A, Y))\n",
    "        #esti = esti - diff_m\n",
    "        bottom = esti + eps\n",
    "        #print(\"lav\",np.shape(top/bottom))\n",
    "        tb = top / bottom\n",
    "        #print(np.linalg.norm(tb))\n",
    "        no = np.linalg.norm(tb)\n",
    "        #Y *= tb\n",
    "        Y *= (0.9 * tb) + ( 0.1 * ( tb + (1/no) )  )\n",
    "        \n",
    "        \"\"\"\n",
    "        ## Regularization\n",
    "        if i % 10 == 0:\n",
    "            diff = np.abs(Y - prev_Y)\n",
    "            diff = diff - 0.001\n",
    "            Y = np.sign(diff)*Y\n",
    "            prev_Y = Y\n",
    "        \"\"\"\n",
    "\n",
    "        # evaluation\n",
    "        if i % 10 == 0 or i == 1 or i == max_iter:\n",
    "            X_est = np.dot(A, Y)\n",
    "            q = masktest*X_est - rawMatrixTest\n",
    "            q_train = masktrain*X_est - rawMatrixTrain\n",
    "            print(np.linalg.norm(tb))\n",
    "            print \"Iteration %d, Err %.05f, Err train %.05f\"%( i, (q*q).sum()/ masktest.sum(), (q_train*q_train).sum()/ masktest.sum() )\n",
    "            \n",
    "    return A, Y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This is quite unstable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NMF with 1 latent features, 100 iterations.\n",
      "2269.30475923\n",
      "Iteration 1, Err 0.94484, Err train 3.61341\n",
      "40.3112135185\n",
      "Iteration 10, Err 0.88123, Err train 3.36666\n",
      "40.3112902647\n",
      "Iteration 20, Err 0.88123, Err train 3.36666\n",
      "40.3112902218\n",
      "Iteration 30, Err 0.88123, Err train 3.36666\n",
      "40.3112901646\n",
      "Iteration 40, Err 0.88123, Err train 3.36666\n",
      "40.3112901082\n",
      "Iteration 50, Err 0.88123, Err train 3.36666\n",
      "40.3112900527\n",
      "Iteration 60, Err 0.88123, Err train 3.36666\n",
      "40.311289998\n",
      "Iteration 70, Err 0.88123, Err train 3.36666\n",
      "40.311289944\n",
      "Iteration 80, Err 0.88123, Err train 3.36666\n",
      "40.3112898908\n",
      "Iteration 90, Err 0.88123, Err train 3.36666\n",
      "40.3112898383\n",
      "Iteration 100, Err 0.88123, Err train 3.36666\n",
      "CPU times: user 3.53 s, sys: 814 ms, total: 4.34 s\n",
      "Wall time: 3.26 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "X = copy.deepcopy(rawMatrixTrain)\n",
    "A,Y = nmf(X,1,eps = 1e-5,max_iter=100,printevery=10)\n",
    "resMatrix = A.dot(Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### /!\\ 18 movies have no ratings at all\n",
    "so we get a divide by zero warning. Ignored with:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with np.errstate(all='ignore'):\n",
    "    avg_m = rawMatrix.sum(0)/(rawMatrix != 0).sum(0)\n",
    "    avg_u = rawMatrix.sum(1)/(rawMatrix != 0).sum(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.1465785558244217"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "masqueTest=np.sign(rawMatrixTest)\n",
    "q = masqueTest*resMatrix - rawMatrixTest\n",
    "(q*q).sum()/ masqueTest.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mf = evalMF(resMatrix,data,movies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.0\n",
      "3.68121941569\n",
      "1.0\n",
      "0.96164687419\n"
     ]
    }
   ],
   "source": [
    "print data[\"1\"][\"Akira (1988)\"]\n",
    "print mf.predict(\"1\",\"Akira (1988)\")\n",
    "print data[\"1\"][\"All Dogs Go to Heaven 2 (1996)\"]\n",
    "print mf.predict(\"1\",\"All Dogs Go to Heaven 2 (1996)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "943"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(rawMatrixTest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4.0, 3.8396463699257595)\n",
      "(3.0, 3.5458851979095165)\n",
      "(2.0, 3.2755712334736713)\n",
      "(4.0, 3.5087244595199025)\n",
      "(2.0, 2.4510027204018821)\n",
      "(3.0, 3.3214138496532524)\n",
      "(5.0, 3.7460132079987969)\n",
      "(4.0, 4.146715732882595)\n",
      "(5.0, 4.2383683022905867)\n",
      "(3.0, 3.2597595068592664)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.89275690554990295"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = []\n",
    "c = 10\n",
    "for idxi,i in enumerate(rawMatrixTest):\n",
    "    for idxj,j in enumerate(i):\n",
    "        if rawMatrixTest[idxi][idxj] != 0:\n",
    "            t.append( (resMatrix[idxi][idxj] - float(rawMatrixTest[idxi][idxj]))**2 )\n",
    "            if c>0:\n",
    "                print(rawMatrixTest[idxi][idxj],resMatrix[idxi][idxj])\n",
    "                c-=1\n",
    "np.array(t).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "R = rawMatrixTrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def matrix_factorization(R, K, steps=100, eps=0.0001, beta=0.02, decay=0.95):\n",
    "    N,M = np.shape(R)\n",
    "    P = np.random.rand(N,K)\n",
    "    #P = np.maximum(P, eps)\n",
    "    \n",
    "    #Q = np.random.rand(M,K).T\n",
    "    Q = linalg.lstsq(P, R)[0]\n",
    "    Q = np.maximum(Q, eps)\n",
    "\n",
    "    #masked_X = mask * X\n",
    "    #X_est_prev = dot(A, Y)\n",
    "    \n",
    "    #mask = np.sign(R)\n",
    "    #masked_R = mask * R\n",
    "    \n",
    "    masktest = np.sign(rawMatrixTest)\n",
    "    masktrain = np.sign(rawMatrixTrain)\n",
    "    \n",
    "    \n",
    "    for step in xrange(1,steps+1):\n",
    "        #\"\"\"\n",
    "        for i in xrange(len(R)):\n",
    "            for j in xrange(len(R[i])):\n",
    "                if R[i][j] > 0:\n",
    "                    eij = R[i][j] - np.dot(P[i,:],Q[:,j])\n",
    "                    P[i] = P[i] + eps * (2 * eij * Q.T[j] - beta * P[i])\n",
    "                    #Q[i] = P[i] + eps * (2 * eij * Q.T[j] - beta * P[i])\n",
    "                    Q.T[j] = Q.T[j] + eps * (2 * eij * P[i] - beta * Q.T[j])\n",
    "                    #for k in xrange(K):\n",
    "                    #    P[i][k] = P[i][k] + eps * (2 * eij * Q[k][j] - beta * P[i][k])\n",
    "                        #Q[k][j] = Q[k][j] + eps * (2 * eij * P[i][k] - beta * Q[k][j])\n",
    "\n",
    "        if step%5:\n",
    "            eps=eps*decay\n",
    "        \n",
    "        if step % 10 == 0 or step == 1 or step == steps:\n",
    "\n",
    "            X_est = dot(P, Q)\n",
    "            q = masktest*X_est - rawMatrixTest\n",
    "            q_train = masktrain*X_est - rawMatrixTrain\n",
    "            print \"Iteration %d, Err %.05f, Err on train %.05f\"%( step, (q*q).sum()/ masktest.sum(), (q_train*q_train).sum()/ masktest.sum() )\n",
    "            \n",
    "        \n",
    "        \n",
    "    return P, Q.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, Err 3.33905, Err train 12.59114\n",
      "Iteration 10, Err 1.07766, Err train 3.68302\n",
      "Iteration 20, Err 0.98629, Err train 3.23860\n",
      "Iteration 30, Err 0.95904, Err train 3.02876\n",
      "Iteration 40, Err 0.94580, Err train 2.85712\n",
      "Iteration 50, Err 0.93984, Err train 2.70948\n",
      "Iteration 60, Err 0.93874, Err train 2.58756\n",
      "Iteration 70, Err 0.94040, Err train 2.48769\n",
      "Iteration 80, Err 0.94345, Err train 2.40503\n",
      "Iteration 90, Err 0.94717, Err train 2.33584\n",
      "Iteration 100, Err 0.95115, Err train 2.27742\n",
      "CPU times: user 6min 16s, sys: 2.28 s, total: 6min 18s\n",
      "Wall time: 6min 17s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "K = 10\n",
    "nP, nQ = matrix_factorization(R, K, steps=100,eps=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "174.05240132990514"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nR = np.dot(nP, nQ.T)\n",
    "((nR-R)**2).sum()/np.sign(R).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "---\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
