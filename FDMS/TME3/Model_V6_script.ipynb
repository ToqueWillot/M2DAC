{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Python/2.7/site-packages/matplotlib/__init__.py:872: UserWarning: axes.color_cycle is deprecated and replaced with axes.prop_cycle; please use the latter.\n",
      "  warnings.warn(self.msg_depr % (key, alt_key))\n"
     ]
    }
   ],
   "source": [
    "# from __future__ import exam_success\n",
    "from __future__ import absolute_import \n",
    "from __future__ import print_function  \n",
    "\n",
    "# Standard imports\n",
    "%matplotlib inline\n",
    "import os\n",
    "import sklearn\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import random\n",
    "import pandas as pd\n",
    "import scipy.stats as stats\n",
    "\n",
    "# Sk cheats\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "from sklearn import grid_search\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.svm import SVR\n",
    "#from sklearn.preprocessing import Imputer   # get rid of nan\n",
    "from sklearn.decomposition import NMF        # to add features based on the latent representation\n",
    "from sklearn.decomposition import ProjectedGradientNMF\n",
    "\n",
    "# Faster gradient boosting\n",
    "import xgboost as xgb\n",
    "\n",
    "# For neural networks models\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation \n",
    "from keras.optimizers import SGD, RMSprop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STARTED...\n"
     ]
    }
   ],
   "source": [
    "print(\"STARTED...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 44.6 ms, sys: 11.9 ms, total: 56.5 ms\n",
      "Wall time: 61.9 ms\n"
     ]
    }
   ],
   "source": [
    "#filename = \"data/train.csv\"\n",
    "filename = \"data/reduced_train_10000.csv\"\n",
    "raw = pd.read_csv(filename)\n",
    "raw = raw.set_index('Id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOADED\n"
     ]
    }
   ],
   "source": [
    "print(\"LOADED\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropped 678 (6.78%)\n"
     ]
    }
   ],
   "source": [
    "# Considering that the gauge may concentrate the rainfall, we set the cap to 1000\n",
    "# Comment this line to analyse the complete dataset \n",
    "l = len(raw)\n",
    "raw = raw[raw['Expected'] < 300]  #1000\n",
    "print(\"Dropped %d (%0.2f%%)\"%(l-len(raw),(l-len(raw))/float(l)*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# We select all features except for the minutes past,\n",
    "# because we ignore the time repartition of the sequence for now\n",
    "\n",
    "features_columns = list([u'Ref', u'Ref_5x5_10th',\n",
    "       u'Ref_5x5_50th', u'Ref_5x5_90th', u'RefComposite',\n",
    "       u'RefComposite_5x5_10th', u'RefComposite_5x5_50th',\n",
    "       u'RefComposite_5x5_90th', u'RhoHV', u'RhoHV_5x5_10th',\n",
    "       u'RhoHV_5x5_50th', u'RhoHV_5x5_90th', u'Zdr', u'Zdr_5x5_10th',\n",
    "       u'Zdr_5x5_50th', u'Zdr_5x5_90th', u'Kdp', u'Kdp_5x5_10th',\n",
    "       u'Kdp_5x5_50th', u'Kdp_5x5_90th'])\n",
    "\n",
    "def getXy(raw):\n",
    "    selected_columns = list([ u'minutes_past',u'radardist_km', u'Ref', u'Ref_5x5_10th',\n",
    "       u'Ref_5x5_50th', u'Ref_5x5_90th', u'RefComposite',\n",
    "       u'RefComposite_5x5_10th', u'RefComposite_5x5_50th',\n",
    "       u'RefComposite_5x5_90th', u'RhoHV', u'RhoHV_5x5_10th',\n",
    "       u'RhoHV_5x5_50th', u'RhoHV_5x5_90th', u'Zdr', u'Zdr_5x5_10th',\n",
    "       u'Zdr_5x5_50th', u'Zdr_5x5_90th', u'Kdp', u'Kdp_5x5_10th',\n",
    "       u'Kdp_5x5_50th', u'Kdp_5x5_90th'])\n",
    "    \n",
    "    data = raw[selected_columns]\n",
    "    \n",
    "    docX, docY = [], []\n",
    "    for i in data.index.unique():\n",
    "        if isinstance(data.loc[i],pd.core.series.Series):\n",
    "            m = [data.loc[i].as_matrix()]\n",
    "            docX.append(m)\n",
    "            docY.append(float(raw.loc[i][\"Expected\"]))\n",
    "        else:\n",
    "            m = data.loc[i].as_matrix()\n",
    "            docX.append(m)\n",
    "            docY.append(float(raw.loc[i][:1][\"Expected\"]))\n",
    "    X , y = np.array(docX) , np.array(docY)\n",
    "    return X,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "noFullNan = raw.loc[raw[features_columns].dropna(how='all').index.unique()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X,y=getXy(noFullNan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Python/2.7/site-packages/numpy/lib/nanfunctions.py:675: RuntimeWarning: Mean of empty slice\n",
      "  warnings.warn(\"Mean of empty slice\", RuntimeWarning)\n"
     ]
    }
   ],
   "source": [
    "global_means = np.nanmean(noFullNan,0)\n",
    "\n",
    "XX=[]\n",
    "for t in X:\n",
    "    nm = np.nanmean(t,0)\n",
    "    for idx,j in enumerate(nm):\n",
    "        if np.isnan(j):\n",
    "            nm[idx]=global_means[idx]\n",
    "    XX.append(nm)\n",
    "XX=np.array(XX)\n",
    "\n",
    "# rescale to clip min at 0 (for non negative matrix factorization)\n",
    "XX_rescaled=XX[:,:]-np.min(XX,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Python/2.7/site-packages/sklearn/decomposition/nmf.py:252: UserWarning: Iteration limit reached in nls subproblem.\n",
      "  warnings.warn(\"Iteration limit reached in nls subproblem.\")\n"
     ]
    }
   ],
   "source": [
    "\n",
    "nmf = NMF(max_iter=5000)\n",
    "W = nmf.fit_transform(XX_rescaled)\n",
    "#H = nn.components_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# reduce the sequence structure of the data and produce\n",
    "# new hopefully informatives features\n",
    "def addFeatures(X,mf=0):\n",
    "    # used to fill fully empty datas\n",
    "    #global_means = np.nanmean(X,0)\n",
    "    \n",
    "    XX=[]\n",
    "    nbFeatures=float(len(X[0][0]))\n",
    "    for idxt,t in enumerate(X):\n",
    "        \n",
    "        # compute means, ignoring nan when possible, marking it when fully filled with nan\n",
    "        nm = np.nanmean(t,0)\n",
    "        tt=[]\n",
    "        for idx,j in enumerate(nm):\n",
    "            if np.isnan(j):\n",
    "                nm[idx]=global_means[idx]\n",
    "                tt.append(1)\n",
    "            else:\n",
    "                tt.append(0)\n",
    "        tmp = np.append(nm,np.append(tt,tt.count(0)/nbFeatures))\n",
    "        \n",
    "        # faster if working on fully filled data:\n",
    "        #tmp = np.append(np.nanmean(np.array(t),0),(np.array(t)[1:] - np.array(t)[:-1]).sum(0) )\n",
    "        \n",
    "        # add the percentiles\n",
    "        tmp = np.append(tmp,np.nanpercentile(t,10,axis=0))\n",
    "        tmp = np.append(tmp,np.nanpercentile(t,50,axis=0))\n",
    "        tmp = np.append(tmp,np.nanpercentile(t,90,axis=0))\n",
    "        \n",
    "        for idx,i in enumerate(tmp):\n",
    "            if np.isnan(i):\n",
    "                tmp[idx]=0\n",
    "\n",
    "        # adding the dbz as a feature\n",
    "        test = t\n",
    "        try:\n",
    "            taa=test[:,0]\n",
    "        except TypeError:\n",
    "            taa=[test[0][0]]\n",
    "        valid_time = np.zeros_like(taa)\n",
    "        valid_time[0] = taa[0]\n",
    "        for n in xrange(1,len(taa)):\n",
    "            valid_time[n] = taa[n] - taa[n-1]\n",
    "        valid_time[-1] = valid_time[-1] + 60 - np.sum(valid_time)\n",
    "        valid_time = valid_time / 60.0\n",
    "\n",
    "\n",
    "        sum=0\n",
    "        try:\n",
    "            column_ref=test[:,2]\n",
    "        except TypeError:\n",
    "            column_ref=[test[0][2]]\n",
    "        for dbz, hours in zip(column_ref, valid_time):\n",
    "            # See: https://en.wikipedia.org/wiki/DBZ_(meteorology)\n",
    "            if np.isfinite(dbz):\n",
    "                mmperhr = pow(pow(10, dbz/10)/200, 0.625)\n",
    "                sum = sum + mmperhr * hours\n",
    "        \n",
    "        if not(mf is 0):\n",
    "            tmp = np.append(tmp,mf[idxt])\n",
    "\n",
    "        XX.append(np.append(np.array(sum),tmp))\n",
    "        #XX.append(np.array([sum]))\n",
    "        #XX.append(tmp)\n",
    "    return np.array(XX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Python/2.7/site-packages/numpy/lib/nanfunctions.py:993: RuntimeWarning: All-NaN slice encountered\n",
      "  warnings.warn(\"All-NaN slice encountered\", RuntimeWarning)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "XX=addFeatures(X,mf=W)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FEATURES EXTRACTED\n"
     ]
    }
   ],
   "source": [
    "print(\"FEATURES EXTRACTED\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "etreg = ExtraTreesRegressor(n_estimators=200, max_depth=None, min_samples_split=1, n_jobs=8)\n",
    "etreg = etreg.fit(XX,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MODEL 1 TRAINED\n"
     ]
    }
   ],
   "source": [
    "print(\"MODEL 1 TRAINED\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "etreg2 = ExtraTreesRegressor(n_estimators=200, max_depth=None, min_samples_split=1, n_jobs=8)\n",
    "etreg2 = etreg.fit(XX,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MODEL 2 TRAINED\n"
     ]
    }
   ],
   "source": [
    "print(\"MODEL 2 TRAINED\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "etreg3 = ExtraTreesRegressor(n_estimators=200, max_depth=None, min_samples_split=1, n_jobs=8)\n",
    "etreg3 = etreg.fit(XX,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MODEL 3 TRAINED\n"
     ]
    }
   ],
   "source": [
    "print(\"MODEL 3 TRAINED\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#knn,etreg,rfr,xgbr,gbr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict on testset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#filename = \"data/test.csv\"\n",
    "filename = \"data/reduced_test_5000.csv\"\n",
    "test = pd.read_csv(filename)\n",
    "test = test.set_index('Id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST LOADED\n"
     ]
    }
   ],
   "source": [
    "print(\"TEST LOADED\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "features_columns = list([u'Ref', u'Ref_5x5_10th',\n",
    "       u'Ref_5x5_50th', u'Ref_5x5_90th', u'RefComposite',\n",
    "       u'RefComposite_5x5_10th', u'RefComposite_5x5_50th',\n",
    "       u'RefComposite_5x5_90th', u'RhoHV', u'RhoHV_5x5_10th',\n",
    "       u'RhoHV_5x5_50th', u'RhoHV_5x5_90th', u'Zdr', u'Zdr_5x5_10th',\n",
    "       u'Zdr_5x5_50th', u'Zdr_5x5_90th', u'Kdp', u'Kdp_5x5_10th',\n",
    "       u'Kdp_5x5_50th', u'Kdp_5x5_90th'])\n",
    "\n",
    "def getX(raw):\n",
    "    selected_columns = list([ u'minutes_past',u'radardist_km', u'Ref', u'Ref_5x5_10th',\n",
    "       u'Ref_5x5_50th', u'Ref_5x5_90th', u'RefComposite',\n",
    "       u'RefComposite_5x5_10th', u'RefComposite_5x5_50th',\n",
    "       u'RefComposite_5x5_90th', u'RhoHV', u'RhoHV_5x5_10th',\n",
    "       u'RhoHV_5x5_50th', u'RhoHV_5x5_90th', u'Zdr', u'Zdr_5x5_10th',\n",
    "       u'Zdr_5x5_50th', u'Zdr_5x5_90th', u'Kdp', u'Kdp_5x5_10th',\n",
    "       u'Kdp_5x5_50th', u'Kdp_5x5_90th'])\n",
    "    \n",
    "    data = raw[selected_columns]\n",
    "    \n",
    "    docX= []\n",
    "    for i in data.index.unique():\n",
    "        if isinstance(data.loc[i],pd.core.series.Series):\n",
    "            m = [data.loc[i].as_matrix()]\n",
    "            docX.append(m)\n",
    "        else:\n",
    "            m = data.loc[i].as_matrix()\n",
    "            docX.append(m)\n",
    "    X = np.array(docX)\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#%%time\n",
    "#X=getX(test)\n",
    "\n",
    "#tmp = []\n",
    "#for i in X:\n",
    "#    tmp.append(len(i))\n",
    "#tmp = np.array(tmp)\n",
    "#sns.countplot(tmp,order=range(tmp.min(),tmp.max()+1))\n",
    "#plt.title(\"Number of ID per number of observations\\n(On test dataset)\")\n",
    "#plt.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#testFull = test.dropna()\n",
    "testNoFullNan = test.loc[test[features_columns].dropna(how='all').index.unique()]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_X=getX(testNoFullNan)  # 1min\n",
    "#XX = [np.array(t).mean(0) for t in X]  # 10s\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_XX=[]\n",
    "for t in test_X:\n",
    "    nm = np.nanmean(t,0)\n",
    "    for idx,j in enumerate(nm):\n",
    "        if np.isnan(j):\n",
    "            nm[idx]=global_means[idx]\n",
    "    test_XX.append(nm)\n",
    "test_XX=np.array(test_XX)\n",
    "\n",
    "# rescale to clip min at 0 (for non negative matrix factorization)\n",
    "test_XX_rescaled=test_XX[:,:]-np.min(test_XX,0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_W = nmf.transform(test_XX_rescaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_XX=addFeatures(test_X,mf=test_W)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PREDICTING...\n"
     ]
    }
   ],
   "source": [
    "print(\"PREDICTING...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "reducedModelList = [etreg,etreg2,etreg3]\n",
    "test_globalPred = np.array([f.predict(test_XX) for f in reducedModelList]).T\n",
    "predTest = test_globalPred.mean(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "predFull = zip(testNoFullNan.index.unique(),predTest)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "testNan = test.drop(test[features_columns].dropna(how='all').index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tmp = np.empty(len(testNan))\n",
    "tmp.fill(0.445000)   # 50th percentile of full Nan dataset\n",
    "predNan = zip(testNan.index.unique(),tmp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred = predFull + predNan\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pred.sort(key=lambda x: x[0], reverse=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Expected</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2.161731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>17.276049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>3.113642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>6.035318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.445000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id   Expected\n",
       "0   1   2.161731\n",
       "1   2  17.276049\n",
       "2   3   3.113642\n",
       "3   4   6.035318\n",
       "4   5   0.445000"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission = pd.DataFrame(pred)\n",
    "submission.columns = [\"Id\",\"Expected\"]\n",
    "submission.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DUMPING\n"
     ]
    }
   ],
   "source": [
    "print(\"DUMPING\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "submission.loc[submission['Expected']<0,'Expected'] = 0.01\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "submission.to_csv(\"submit6.csv\",index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OVER\n"
     ]
    }
   ],
   "source": [
    "print(\"OVER\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
